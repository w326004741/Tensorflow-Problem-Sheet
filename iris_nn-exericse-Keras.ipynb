{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import keras as kr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 99, 112,  60, 149,  62,  67,   6, 133, 105, 120, 103,  61,  45,\n",
       "        32,  73,  76, 141,  64, 126, 131,  17, 130, 129,   9,  56,   3,\n",
       "        81,  74, 100,   5,  48,  80,  16, 113,  44,  29,  52,  82,  88,\n",
       "        10,  77, 148, 111,  15,  94, 135, 140,  34, 117, 114,  86,   0,\n",
       "        28,  38,  35, 115, 145,  31,  92, 137, 106,  39, 110, 132, 124,\n",
       "       104, 108,  71,  25,  42,  18, 147,   2,  96,  20,  33,  13,  55,\n",
       "        84, 128,  11, 119, 118,  27,   1,  26, 123,  37,  22,  98,  63,\n",
       "        49,  93,  97,   7, 109,  75,  46,  68,  95,  69, 107,  59, 138,\n",
       "        89,  30,  90,  54, 144,  83,   4,  66,  41, 122,  91,  21,  70,\n",
       "        85,  50, 139, 136, 102,  12, 116,  53,  57,  65,  72, 101,  78,\n",
       "        79,  47,  14, 146,  87,  19,  51,  24, 134,  36, 142,  43,  40,\n",
       "       127, 121,   8,  23,  58, 143, 125])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = list(csv.reader(open('irisdata.csv')))[1:] #[1:] 省略第一行 类似于 skip_header=1\n",
    "# iris\n",
    "# The inputs are four floats: sepal length, sepal width, petal length, petal width.\n",
    "inputs = np.array(iris)[:,:4].astype(np.str) #将iris数列化，[:,:4]只显示4列，input.[ordernodes(所有提供的):.:youneednodes(你需要的)]\n",
    "# inputs\n",
    "# Outputs are initially individual strings: setosa, versicolor or virginica.\n",
    "outputs = np.array(iris)[:,4] # output只输出[:,4] 第四列的内容(iris.csv表里有5列(0-4列)，第四列是species名称)\n",
    "# outputs\n",
    "outputs_vals, outputs_ints = np.unique(outputs, return_inverse=True)# return_inverse=True 输出数组里的唯一值\n",
    "# outputs_vals # 输出唯一species名称 （string值）\n",
    "# outputs_ints # 输出数组的编码指数(int值)，从0开始, like 0,1,2...\n",
    "outputs_cats = kr.utils.to_categorical(outputs_ints) # Encode the category integers as binary categorical variables.\n",
    "# outputs_cats #将数组以二进制编码类型输出 分别代表每种sepecies名称，setosa(1,0,0), versicolor(0,1,0),virginica(0,0,1)\n",
    "\n",
    "inds = np.random.permutation(len(inputs))# 随机排列一个序列，或者返回一个排列的范围.\n",
    "train_inds, test_inds = np.array_split(inds, 2)# 将数组拆分成多个子数组. 拆分成 train_inds 和 test_inds 数组\n",
    "# train_inds\n",
    "# test_inds\n",
    "# inputs_train输出input值的train_inds, output_train输出二进制类的train_inds\n",
    "inputs_train, outputs_train = inputs[train_inds], outputs_cats[train_inds]\n",
    "# inputs_train,outputs_train\n",
    "# inputs_train输出input值的test_inds, output_train输出二进制类的test_inds\n",
    "inputs_test, outputs_test = inputs[test_inds], outputs_cats[test_inds]\n",
    "# inputs_test, outputs_test\n",
    "inds = np.random.permutation(len(inputs))\n",
    "# train_ind\n",
    "#outputs_cats\n",
    "inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 1.0106 - acc: 0.3200\n",
      "Epoch 2/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.7818 - acc: 0.6533\n",
      "Epoch 3/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.6931 - acc: 0.7333\n",
      "Epoch 4/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.6361 - acc: 0.7067\n",
      "Epoch 5/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.5970 - acc: 0.7600\n",
      "Epoch 6/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.5444 - acc: 0.8533\n",
      "Epoch 7/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.5145 - acc: 0.7600\n",
      "Epoch 8/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.4945 - acc: 0.7733\n",
      "Epoch 9/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.4710 - acc: 0.8533\n",
      "Epoch 10/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.4430 - acc: 0.8533\n",
      "Epoch 11/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.4284 - acc: 0.8133\n",
      "Epoch 12/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.4078 - acc: 0.9067\n",
      "Epoch 13/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.3946 - acc: 0.8800\n",
      "Epoch 14/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.3863 - acc: 0.9200\n",
      "Epoch 15/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.3744 - acc: 0.9067\n",
      "Epoch 16/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.3616 - acc: 0.8800\n",
      "Epoch 17/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.3523 - acc: 0.9067\n",
      "Epoch 18/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.3305 - acc: 0.8933\n",
      "Epoch 19/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.3376 - acc: 0.9467\n",
      "Epoch 20/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.3137 - acc: 0.9600\n",
      "Epoch 21/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.3112 - acc: 0.9200\n",
      "Epoch 22/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.3006 - acc: 0.9600\n",
      "Epoch 23/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.2886 - acc: 0.9333\n",
      "Epoch 24/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.2909 - acc: 0.9333\n",
      "Epoch 25/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.2788 - acc: 0.9467\n",
      "Epoch 26/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.2660 - acc: 0.9467\n",
      "Epoch 27/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.2714 - acc: 0.9600\n",
      "Epoch 28/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.2576 - acc: 0.9733\n",
      "Epoch 29/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.2527 - acc: 0.9200\n",
      "Epoch 30/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.2618 - acc: 0.9200\n",
      "Epoch 31/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.2541 - acc: 0.9467\n",
      "Epoch 32/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.2355 - acc: 0.9600\n",
      "Epoch 33/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.2355 - acc: 0.9600\n",
      "Epoch 34/100\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2283 - acc: 0.9600\n",
      "Epoch 35/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.2187 - acc: 0.9600\n",
      "Epoch 36/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.2254 - acc: 0.9600\n",
      "Epoch 37/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.2143 - acc: 0.9733\n",
      "Epoch 38/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.2045 - acc: 0.9600\n",
      "Epoch 39/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.2094 - acc: 0.9467\n",
      "Epoch 40/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.2021 - acc: 0.9733\n",
      "Epoch 41/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1921 - acc: 0.9733\n",
      "Epoch 42/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1831 - acc: 0.9733\n",
      "Epoch 43/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.2019 - acc: 0.9467\n",
      "Epoch 44/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1827 - acc: 0.9733\n",
      "Epoch 45/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1808 - acc: 0.9600\n",
      "Epoch 46/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1817 - acc: 0.9600\n",
      "Epoch 47/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1861 - acc: 0.9600\n",
      "Epoch 48/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1763 - acc: 0.9733\n",
      "Epoch 49/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1724 - acc: 0.9600\n",
      "Epoch 50/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1722 - acc: 0.9600\n",
      "Epoch 51/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1759 - acc: 0.9600\n",
      "Epoch 52/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1651 - acc: 0.9467\n",
      "Epoch 53/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1647 - acc: 0.9600\n",
      "Epoch 54/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1682 - acc: 0.9600\n",
      "Epoch 55/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1530 - acc: 0.9600\n",
      "Epoch 56/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1484 - acc: 0.9867\n",
      "Epoch 57/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1522 - acc: 0.9733\n",
      "Epoch 58/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1519 - acc: 0.9333\n",
      "Epoch 59/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1596 - acc: 0.9600\n",
      "Epoch 60/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1408 - acc: 0.9733\n",
      "Epoch 61/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1427 - acc: 0.9600\n",
      "Epoch 62/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1419 - acc: 0.9600\n",
      "Epoch 63/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1393 - acc: 0.9600\n",
      "Epoch 64/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1346 - acc: 0.9600\n",
      "Epoch 65/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1323 - acc: 0.9600\n",
      "Epoch 66/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1335 - acc: 0.9467\n",
      "Epoch 67/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1333 - acc: 0.9467\n",
      "Epoch 68/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1379 - acc: 0.9600\n",
      "Epoch 69/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1416 - acc: 0.9733\n",
      "Epoch 70/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1363 - acc: 0.9600\n",
      "Epoch 71/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1300 - acc: 0.9600\n",
      "Epoch 72/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1243 - acc: 0.9600\n",
      "Epoch 73/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1297 - acc: 0.9467\n",
      "Epoch 74/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1278 - acc: 0.9467\n",
      "Epoch 75/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1227 - acc: 0.9600\n",
      "Epoch 76/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1327 - acc: 0.9467\n",
      "Epoch 77/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1153 - acc: 0.9867\n",
      "Epoch 78/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1269 - acc: 0.9600\n",
      "Epoch 79/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1213 - acc: 0.9733\n",
      "Epoch 80/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1221 - acc: 0.9733\n",
      "Epoch 81/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.1151 - acc: 0.9600\n",
      "Epoch 82/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1191 - acc: 0.9600\n",
      "Epoch 83/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1174 - acc: 0.9733\n",
      "Epoch 84/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1284 - acc: 0.9467\n",
      "Epoch 85/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1152 - acc: 0.9467\n",
      "Epoch 86/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1132 - acc: 0.9600\n",
      "Epoch 87/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1175 - acc: 0.9600\n",
      "Epoch 88/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1145 - acc: 0.9600\n",
      "Epoch 89/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1106 - acc: 0.9600\n",
      "Epoch 90/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1085 - acc: 0.9600\n",
      "Epoch 91/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1044 - acc: 0.9733\n",
      "Epoch 92/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1061 - acc: 0.9600\n",
      "Epoch 93/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1160 - acc: 0.9600\n",
      "Epoch 94/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1010 - acc: 0.9600\n",
      "Epoch 95/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1050 - acc: 0.9733\n",
      "Epoch 96/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1100 - acc: 0.9600\n",
      "Epoch 97/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1135 - acc: 0.9600\n",
      "Epoch 98/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1071 - acc: 0.9733\n",
      "Epoch 99/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1064 - acc: 0.9600\n",
      "Epoch 100/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1063 - acc: 0.9600\n",
      "75/75 [==============================] - 0s 607us/step\n",
      "\n",
      "\n",
      "Loss: 0.1098\tAccuracy: 0.9733\n"
     ]
    }
   ],
   "source": [
    "# https://www.cnblogs.com/arkenstone/p/5943489.html?utm_source=itdadao&utm_medium=referral\n",
    "# Create a neural network\n",
    "model = kr.models.Sequential() # 神经层\n",
    "model.add(kr.layers.Dense(16, input_shape=(4,))) # 16是output_dim=hidden layer隐藏层，initial layer有4个node(4个属性(length,width)),\n",
    "#input_shape=(4,)=input_dim,也就是从data set里读取(学习)所有的数据，然后压到16个单位.\n",
    "model.add(kr.layers.Activation(\"relu\")) # 然后把16放到Activation function,用sigmoid作Activation Function\n",
    "model.add(kr.layers.Dense(3)) # 第二层神经网络，输出为3个单位，从16个单位压到3个单位.\n",
    "\n",
    "model.add(kr.layers.Activation(\"softmax\")) # 输出Activation Function,用softmax进行分类,激活函数\n",
    "# 定义loss function用categorical_crossentropy分类交叉，通过metrics计算accuracy(准确率)，loss=丢失率\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])# metrics=[\"accuracy\"] 精确到一个\n",
    "# epochs=100是有100次的train训练，batch_size为每次训练样品个数，verbose: 0表示不更新日志, 1更新日志, 2每个epoch一个进度行. \n",
    "model.fit(inputs_train, outputs_train, epochs=100, batch_size=1, verbose=1)\n",
    "\n",
    "loss, accuracy = model.evaluate(inputs_test, outputs_test, verbose=1)\n",
    "print(\"\\n\\nLoss: %6.4f\\tAccuracy: %6.4f\" % (loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: [1 0 0]\tEstimated: [1 0 0]\n",
      "That means it's a setosa\n"
     ]
    }
   ],
   "source": [
    "# http://blog.csdn.net/rango_lhl/article/details/50542887 (axis=0)\n",
    "# https://docs.scipy.org/doc/numpy/reference/generated/numpy.around.html (np.around)\n",
    "# axis=0表述列 axis=1表述行\n",
    "# np.around: 均匀地舍入给定的小数位数. 四舍五入\n",
    "# inputs_test[-74 ~ +74]\n",
    "# prediction内的inputs_test[](species名字)对应outputs_test[](二进制型 outputs_cats[]) \n",
    "# prediction 控制 Estimated(估计值), outputs_test[]控制Actual（实际值）.\n",
    "prediction = np.around(model.predict(np.expand_dims(inputs_test[12],axis=0))).astype(np.int)[0]\n",
    "print(\"Actual: %s\\tEstimated: %s\" % (outputs_test[12].astype(np.int), prediction))\n",
    "print(\"That means it's a %s\" % outputs_vals[prediction.astype(np.bool)][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/35074549/how-to-load-a-model-from-an-hdf5-file-in-keras\n",
    "# http://blog.csdn.net/philosophyatmath/article/details/52774666\n",
    "from keras.models import load_model\n",
    "# Save the model to a file for later use.\n",
    "model.save(\"iris_nn.h5\") # 将模型权重保存到指定路径，文件类型是HDF5（后缀是.h5）\n",
    "# Load the model again with: model = load_model(\"iris_nn.h5\")\n",
    "model = load_model(\"iris_nn.h5\")\n",
    "# 加载已经存在的权值数据到程序中的模型里面。文件中的模型和程序中的模型结构必须一致。在compile之前或之后都可以调用load_ weights函数。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
